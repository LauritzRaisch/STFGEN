# STFGEN

This repository is an assortment of ai and non ai tools to act as a "shit to footage generator".
It is supposed to take footage and data of diffrent quality levels and polish them to a level that is usable for ICVFX.

IMAGE ENHANCEMENT:
- Denoising, Upscaling, Frame interpolation, Deblurring, Space-Time Video Superresolution:\
  https://github.com/JingyunLiang/VRT#quick-testing
  
- Deep Video Denoising:\
  https://github.com/m-tassano/fastdvdnet

- video stabilisation\
  https://github.com/fairuzn/video_image_stabilisation
  
  
  
NERF:
- large scale NERF (Block-Nerf):\
  https://github.com/dvlab-research/LargeScaleNeRFPytorch

- Block-NeRF:\
  https://github.com/hjxwhy/Block-NeRF
  
- Nerf ++:\
  https://github.com/Kai-46/nerfplusplus
  
- Nvidia instant-nerf:\
  https://github.com/NVlabs/instant-ngp
  
- Nvidia Game Works NeRF:\
  https://github.com/NVIDIAGameWorks/kaolin-wisp
 
- Google Multi-Nerf:\
  https://github.com/google-research/multinerf
  
- Nerf 360:\
  https://github.com/Harry-OBrien/Mip-NeRF-360/tree/main
  
- SchenRF:\
  https://github.com/astra-vision/SceneRF
  
  
MONOCULAR DEPTH:
- Intel MiDaS:\
  https://github.com/isl-org/MiDaS
  https://pytorch.org/hub/intelisl_midas_v2/
  add to google collab: cv2.imwrite("output.tiff", output)
- Facebook Indoor Depth:\
  https://github.com/facebookresearch/DistDepth
- Monodepth2:\
  https://github.com/nianticlabs/monodepth2
- Towards real-time unsupervised monocular depth estimation on CPU:\
  https://github.com/mattpoggi/pydnet
- Toyota PackNet-SfM: 3D Packing for Self-Supervised Monocular Depth Estimation:\
  https://github.com/TRI-ML/packnet-sfm
- PanoFormer, Panorama Transformer for Indoor 360Â° Depth Estimation:\
  https://github.com/zhijieshen-bjtu/PanoFormer


3D INPAINTING:\
- 3D Photo inpainting:\
  https://github.com/vt-vl-lab/3d-photo-inpainting



3D:
- Texture upscaling:\
  https://github.com/NVIDIAGameWorks/NVIDIAImageScaling
- Facebook 2D Image of Human to 3D Model:\
  https://github.com/facebookresearch/pifuhd
- 2D Video of Human to 3D Model:\
  https://moygcc.github.io/vid2avatar/
  https://github.com/MoyGcc/vid2avatar



STYLE TRANSFER:
- Fast Style Transfer:\
  https://github.com/lengstrom/fast-style-transfer
- Unreal Engine Style Transfer:\
  https://github.com/microsoft/OnnxRuntime-UnrealEngine


TRACKING & Phtotogrammerty:\
- Working with Motion Tracking:\
  https://github.com/facebookresearch/fairmotion
- 3D pose estimation:\
  https://github.com/facebookresearch/VideoPose3D
- Facebook motion vectors from video:\
  https://github.com/facebookresearch/motion-search
- Fast and Lightweight Scene Regressor for Camera Re-Localization:\
  https://github.com/ais-lab/feat2map
- SLAM DEEP VO:\
  https://github.com/ChiWeiHsiao/DeepVO-pytorch
- Shine:\
  https://github.com/PRBonn/SHINE_mapping
- DeepV2D: Video to Depth with Differentiable Structure from Motion\
  https://github.com/princeton-vl/DeepV2D
  
GOOGLE EARTH IMPORTER:\
- https://github.com/eliemichel/MapsModelsImporter

POINTCLOUD TO MESH:\
- https://github.com/ErlerPhilipp/points2surf
